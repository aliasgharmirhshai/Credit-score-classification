{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path=\"../data/\"):\n",
    "    \"\"\"Load the credit scoring dataset.\"\"\"\n",
    "    # Check if the data directory exists\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"Data directory '{data_path}' not found.\")\n",
    "    \n",
    "    # Look for CSV files in the data directory\n",
    "    csv_files = [f for f in os.listdir(data_path) if f.endswith('train.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in '{data_path}'.\")\n",
    "    \n",
    "    # Load the first CSV file found\n",
    "    file_path = os.path.join(data_path, csv_files[0])\n",
    "    print(f\"Loading data from: {file_path}\")\n",
    "    \n",
    "    return pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"Number of rows : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "total_memory = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "print(f\"Total data memory usage: {total_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"List all column names :\\n\\n {df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"Number of columns :â€Œ {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.clean_data import report_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "report_missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure & Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Types \n",
    "- Check data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "unique_months = df['Month'].unique()\n",
    "print(unique_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical vs. Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"Categorical Columns:\", categorical_columns)\n",
    "print(\"Numerical Columns:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "discrete_vars = [col for col in numerical_columns if df[col].nunique() < 100 and df[col].dtype == 'int64']\n",
    "continuous_vars = [col for col in numerical_columns if df[col].dtype == 'float64' or df[col].nunique() >= 100]\n",
    "print(\"Discrete Variables:\", discrete_vars)\n",
    "print(\"Continuous Variables:\", continuous_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# summary statistics for numerical\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summary_stats(df, categorical_columns=None):\n",
    "    \"\"\"\n",
    "    Generate summary statistics for categorical variables in a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to analyze\n",
    "    categorical_columns (list, optional): List of categorical column names to analyze.\n",
    "                                         If None, will try to identify categorical columns.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary where keys are column names and values are dictionaries of summary statistics\n",
    "    \"\"\"    \n",
    "    # If no categorical columns specified, try to identify them\n",
    "    if categorical_columns is None:\n",
    "        # Select object, category, and boolean dtypes\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "        \n",
    "        # Also include numeric columns with low cardinality (fewer than 10 unique values)\n",
    "        for col in df.select_dtypes(include=['number']).columns:\n",
    "            if df[col].nunique() < 10:\n",
    "                categorical_columns.append(col)\n",
    "    \n",
    "    summary = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Basic stats\n",
    "        value_counts = df[col].value_counts()\n",
    "        unique_values = df[col].unique()\n",
    "        missing_values = df[col].isna().sum()\n",
    "        \n",
    "        # Get mode (most frequent value)\n",
    "        mode_value = df[col].mode()[0] if not df[col].empty else None\n",
    "        mode_count = value_counts.iloc[0] if not value_counts.empty else 0\n",
    "        mode_percentage = (mode_count / len(df)) * 100 if len(df) > 0 else 0\n",
    "        \n",
    "        # Get top 5 categories with counts and percentages\n",
    "        top_categories = []\n",
    "        for value, count in value_counts.head(5).items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            top_categories.append({\n",
    "                'value': value,\n",
    "                'count': count,\n",
    "                'percentage': round(percentage, 2)\n",
    "            })\n",
    "        \n",
    "        # Compile column summary\n",
    "        summary[col] = {\n",
    "            'unique_values': len(unique_values),\n",
    "            'missing_values': missing_values,\n",
    "            'missing_percentage': round((missing_values / len(df)) * 100, 2) if len(df) > 0 else 0,\n",
    "            'mode': {\n",
    "                'value': mode_value,\n",
    "                'count': mode_count,\n",
    "                'percentage': round(mode_percentage, 2)\n",
    "            },\n",
    "            'top_categories': top_categories,\n",
    "            'all_categories': [str(v) for v in unique_values]\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summary_stats_result(col_name):\n",
    "    cat_stats = categorical_summary_stats(df)\n",
    "    stats = cat_stats[col_name]\n",
    "    print(f\"Summary for {col_name}:\")\n",
    "    print(f\"- Unique values: {stats['unique_values']}\")\n",
    "    print(f\"- Most common value: {stats['mode']['value']} (occurs {stats['mode']['percentage']}% of the time)\")\n",
    "    print(f\"- Top categories:\")\n",
    "    for cat in stats['top_categories']:\n",
    "        print(f\"  â€¢ {cat['value']}: {cat['count']} ({cat['percentage']}%)\")\n",
    "    # print(f\"\\n {stats['all_categories']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "categorical_columns = [\n",
    "    \"Occupation\", \n",
    "    \"Type_of_Loan\", \n",
    "    \"Credit_Mix\", \n",
    "    \"Payment_of_Min_Amount\", \n",
    "    \"Payment_Behaviour\", \n",
    "    \"Credit_Score\"\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    categorical_summary_stats_result(col)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    unique_types = set(df[col].apply(type))\n",
    "    if len(unique_types) > 1:\n",
    "        print(f\"Column '{col}' has mixed types: {unique_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Special Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.Type_of_Loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "z_scores = stats.zscore(df['Monthly_Inhand_Salary'])\n",
    "(df['z_score'] > 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
